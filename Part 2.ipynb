{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T21:00:36.522780Z",
     "start_time": "2024-06-10T21:00:35.443137Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import spatial \n",
    "import faiss\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f09c59a02a3b0d",
   "metadata": {},
   "source": [
    "## Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a991f1eb012a476",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T21:00:44.538572Z",
     "start_time": "2024-06-10T21:00:44.525608Z"
    }
   },
   "outputs": [],
   "source": [
    "def semi_optimized_exhaustive_search(\n",
    "        index_vectors: np.ndarray,\n",
    "        query_vectors: np.ndarray,\n",
    "        k: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    This function performs an optimized exhaustive search.\n",
    "    Args:\n",
    "        index_vectors: An array of shape (n_index, dim) containing the index vectors.\n",
    "        query_vectors: An array of shape (n_queries, dim) containing the query vectors. \n",
    "        dim: The dimensionality of the vectors.\n",
    "    Returns:\n",
    "        An array of shape (n_queries, k) containing the indices of the k nearest neighbors for each query vector.\n",
    "    \"\"\"\n",
    "    ann_lists = []\n",
    "    for query_vec in query_vectors:\n",
    "        distances = np.linalg.norm(index_vectors - query_vec, axis=1)\n",
    "        ann_lists.append(list(np.argsort(distances)[:k]))\n",
    "    return np.array(ann_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8ef475c717fbe2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T21:00:47.719310Z",
     "start_time": "2024-06-10T21:00:47.698362Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_faiss_flatl2_index(\n",
    "        index_vectors: np.ndarray,\n",
    "        dim: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    This function builds a Faiss flat L2 index.\n",
    "    Args:\n",
    "        index_vectors: An array of shape (n_index, dim) containing the index vectors.\n",
    "        dim: The dimensionality of the vectors. \n",
    "    Returns:\n",
    "        A Faiss flat L2 index.\n",
    "    \"\"\"\n",
    "    index = faiss.IndexFlatL2(dim)\n",
    "    index.add(index_vectors)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1df7a2d698755a82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T21:00:48.174553Z",
     "start_time": "2024-06-10T21:00:48.157599Z"
    }
   },
   "outputs": [],
   "source": [
    "def faiss_search(\n",
    "        query_vectors: np.ndarray,\n",
    "        index: faiss.Index,\n",
    "        k: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    This function uses a Faiss index to search for the k-nearest neighbors of query_vectors.\n",
    "    Args:\n",
    "        query_vectors: An array of shape (n_queries, dim) containing the query vectors. \n",
    "        index: A Faiss index.\n",
    "        k: The number of nearest neighbors to retrieve.\n",
    "    Returns:\n",
    "        An array of shape (, ) containing the indices of the k-nearest neighbors for each query vector.\n",
    "    \"\"\"\n",
    "    distances, indices = index.search(query_vectors, k)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af14bea64023a3d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T21:00:49.337476Z",
     "start_time": "2024-06-10T21:00:49.325508Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_faiss_lsh_index(\n",
    "        index_vectors: np.ndarray,\n",
    "        dim: int,\n",
    "        nbits: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    This function builds a Faiss LSH index.\n",
    "    Args:\n",
    "        index_vectors: An array of shape (n_index, dim) containing the index vectors.\n",
    "        dim: The dimensionality of the vectors. \n",
    "        nbits: The number of bits to use in the hash.\n",
    "    Returns:\n",
    "        A Faiss LSH index.\n",
    "    \"\"\"\n",
    "    index = faiss.IndexLSH(dim, nbits)\n",
    "    index.add(index_vectors)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4b0932dfa7d7a4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T21:00:49.732824Z",
     "start_time": "2024-06-10T21:00:49.718871Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_recall_at_k(\n",
    "        nn_gt: np.ndarray,\n",
    "        ann: np.ndarray,\n",
    "        k: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    This function computes the recall@k.\n",
    "    Args:\n",
    "        nn_gt: The ground truth nearest neighbors.\n",
    "        ann: The approximate nearest neighbors.\n",
    "        k: The number of nearest neighbors to consider.\n",
    "    Returns:\n",
    "        The recall@k.\n",
    "    \"\"\"\n",
    "    return round(sum([len(set(ann[i]) & set(nn_gt[i])) / k for i in range(len(ann))])/len(ann), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d4be2e90ed842",
   "metadata": {},
   "source": [
    "# 2.1 -- LSH vs Naive Exhaustive Search (Regular Index Vectors)\n",
    "### You just have to run the following cells and add the following results to the report:\n",
    "* running time of the ground truth computation with semi_optimized_exhaustive_search (wall time)\n",
    "* running time of creating faiss_lsh_index (wall time)\n",
    "* running time of faiss_search over query_vectors with faiss_lsh_index (wall time)\n",
    "* recall@10 for faiss_lsh_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4fdbd7671405821",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T21:00:52.378174Z",
     "start_time": "2024-06-10T21:00:52.351252Z"
    }
   },
   "outputs": [],
   "source": [
    "query_vectors = np.load('data/query_vectors.npy')\n",
    "index_vectors = np.load('data/index_vectors.npy')\n",
    "k=10\n",
    "dim = index_vectors.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09632bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vectors2 = np.load('data/query_vectors2.npy')\n",
    "index_vectors2 = np.load('data/index_vectors2.npy')\n",
    "\n",
    "query_vectors3 = np.load('data/query_vectors3.npy')\n",
    "index_vectors3 = np.load('data/index_vectors3.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65ff74d429524ffc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T21:18:41.035362Z",
     "start_time": "2024-06-10T21:18:41.017409Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 14.2 s\n",
      "Wall time: 25.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gt_nn = semi_optimized_exhaustive_search(index_vectors, query_vectors, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78422209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.5 s\n",
      "Wall time: 46.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gt_nn2 = semi_optimized_exhaustive_search(index_vectors2, query_vectors2, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87f0024e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 19.1 s\n",
      "Wall time: 22.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gt_nn3 = semi_optimized_exhaustive_search(index_vectors3, query_vectors3, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd448cbdb96b1ba0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T21:18:36.008226Z",
     "start_time": "2024-06-10T21:18:35.998251Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.58 s\n",
      "Wall time: 969 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "faiss_lsh_index = build_faiss_lsh_index(index_vectors, dim, nbits=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0a321e6b7406267",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T21:18:32.391344Z",
     "start_time": "2024-06-10T21:18:32.385337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 734 ms\n",
      "Wall time: 122 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "faiss_lsh_ann = faiss_search(query_vectors, faiss_lsh_index, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5554595c4d77a27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T21:18:26.322703Z",
     "start_time": "2024-06-10T21:18:26.233820Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall@10 for faiss_lsh_index: 0.138\n"
     ]
    }
   ],
   "source": [
    "print(f\"recall@10 for faiss_lsh_index: {compute_recall_at_k(gt_nn, faiss_lsh_ann, k)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5ca983b3a893e5",
   "metadata": {},
   "source": [
    "# 2.2 -- Custom Indexing Algorithm\n",
    "Build an indexing algorithm that satisfies the following requirements:\n",
    "* The indexing algorithm should be able to handle vectors of different dimensions\n",
    "* The running time of the indexing should be less than half of the running time of semi_optimized_exhaustive_search), reported in Section 2.1.\n",
    "* The running time of searching over the index should be less than a third (1/3) of the time of the semi_optimized_exhaustive_search function, reported in Section 2.1.\n",
    "* The performance (in terms of recall@10) of the indexing algorithm should be at least 0.8.\n",
    "\n",
    "The last three bullets should also appear in the report.\n",
    "You are allowed to add as many helper functions as you need. You cannot use faiss of scipy libraries for this task. Numpy is allowed. \n",
    "\n",
    "You can also test your algorithm with the additional two query-index sets by replacing the calls made few cells ago to:\n",
    "\n",
    "    query_vectors = np.load('data/query_vectors2.npy')\n",
    "    index_vectors = np.load('data/index_vectors2.npy')\n",
    "or:\n",
    "\n",
    "    query_vectors = np.load('data/query_vectors3.npy')\n",
    "    index_vectors = np.load('data/index_vectors3.npy')\n",
    "    \n",
    "the aforementioned requirements should also be satisfied over these two query-index sets. No need to insert the results over these two to the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "669d7713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "class SimpleLSH:\n",
    "    def __init__(self):\n",
    "        # self.num_hashes = num_hashes # some func of dim, k?\n",
    "        self.hash_table = defaultdict(list)\n",
    "\n",
    "    def generate_hash_functions(self, num_vectors, dim):\n",
    "        # Generate random normal hash functions\n",
    "        self.hash_functions = [np.random.randn(dim) for _ in range(12)]\n",
    "\n",
    "    def hash(self, vec):\n",
    "        return tuple([int(np.dot(h, vec) > 0) for h in self.hash_functions])\n",
    "    \n",
    "    def fit(self, index_vectors):\n",
    "        self.index_vectors = index_vectors\n",
    "        self.generate_hash_functions(*index_vectors.shape)\n",
    "        for i, vec in enumerate(self.index_vectors):\n",
    "            hash_key = self.hash(vec)\n",
    "            self.hash_table[hash_key].append(i)\n",
    "        # self.balance_hash_table()\n",
    "\n",
    "    def euclidean_distance(self, vec1, vec2):\n",
    "        # Euclidean distance implementation\n",
    "        return np.linalg.norm(vec1 - vec2)\n",
    "    \n",
    "    def hamming_distance(self, key1, key2):\n",
    "        # Hamming distance implementation\n",
    "        return sum(el1 != el2 for el1, el2 in zip(key1, key2))\n",
    "\n",
    "    # def balance_hash_table(self):\n",
    "    #     small_keys = [key for key in self.hash_table.keys() if len(self.hash_table[key]) < 50]\n",
    "    #     large_keys = [key for key in self.hash_table.keys() if len(self.hash_table[key]) >= 800]\n",
    "\n",
    "\n",
    "    # def increase_values(self, small_keys):\n",
    "    #     for hash_key in small_keys:\n",
    "    #         num_vectors = len(self.hash_table[hash_key])\n",
    "            \n",
    "    #         # Calculate the mean of the vectors\n",
    "    #         mean_vector = np.mean([self.index_vectors[i] for i in self.hash_table[hash_key]], axis=0)\n",
    "\n",
    "    #         # Find the closest vectors from other hash keys\n",
    "    #         soretd_keys = sorted([(self.hamming_distance(hash_key, other_key), other_key) \n",
    "    #                                 for other_key in self.hash_table.keys()], key=lambda x: x[0])[1:]\n",
    "    #         soretd_keys = [other_key for _, other_key in soretd_keys]\n",
    "    #         chosen_keys = [soretd_keys[0]]\n",
    "    #         for other_key in soretd_keys:\n",
    "    #             if len(self.hash_table[other_key]) + num_vectors > 50:\n",
    "    #                 break\n",
    "    #             else:\n",
    "    #                 chosen_keys.append(other_key)\n",
    "    #                 num_vectors += len(self.hash_table[other_key])\n",
    "\n",
    "    #         candidate_vectors = []\n",
    "    #         for key in chosen_keys:\n",
    "    #             candidate_vectors += self.hash_table[key]\n",
    "                \n",
    "    #         distances = [(self.euclidean_distance(mean_vector, self.index_vectors[i]), i) for i in candidate_vectors]\n",
    "\n",
    "    #         # Find the 10 smallest distances\n",
    "    #         smallest_distances = heapq.nsmallest(50-num_vectors, distances)  \n",
    "\n",
    "    #         # Add the indices of the 50 closest vectors to the hash table entry for the current hash key\n",
    "    #         self.hash_table[hash_key].extend(index for _, index in smallest_distances)\n",
    "        \n",
    "\n",
    "    def search(self, query_vec, k):\n",
    "        hash_key = self.hash(query_vec)\n",
    "        if hash_key not in self.hash_table:\n",
    "            return []\n",
    "        # Compute distances and get the indices\n",
    "        distances = [(self.euclidean_distance(query_vec, self.index_vectors[i]), i) for i in self.hash_table[hash_key]]    \n",
    "        # Find the k smallest distances\n",
    "        k_smallest = heapq.nsmallest(k, distances)        \n",
    "        # Extract the indices of the k smallest distances\n",
    "        k_smallest_indices = [index for _, index in k_smallest]\n",
    "        # print(k_smallest)\n",
    "        # print(k_smallest_indices)\n",
    "        \n",
    "        return k_smallest_indices\n",
    "    \n",
    "    def search_all(self, query_vectors, k):\n",
    "        return [self.search(query_vec, k) for query_vec in query_vectors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8d2a420e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import heapq\n",
    "# from collections import defaultdict\n",
    "# import random\n",
    "\n",
    "# class SimpleLSH:\n",
    "#     def __init__(self, num_tables=5, num_hashes=12):\n",
    "#         self.num_tables = num_tables\n",
    "#         self.num_hashes = num_hashes\n",
    "#         self.hash_tables = [defaultdict(list) for _ in range(self.num_tables)]\n",
    "\n",
    "#     def generate_hash_functions(self, num_vectors, dim):\n",
    "#         self.hash_functions = [[np.random.randn(dim) for _ in range(self.num_hashes)] for _ in range(self.num_tables)]\n",
    "\n",
    "#     def hash(self, vec, table_index):\n",
    "#         return tuple([int(np.dot(h, vec) > 0) for h in self.hash_functions[table_index]])\n",
    "\n",
    "#     def fit(self, index_vectors):\n",
    "#         self.index_vectors = index_vectors\n",
    "#         self.generate_hash_functions(*index_vectors.shape)\n",
    "#         for i, vec in enumerate(self.index_vectors):\n",
    "#             for table_index in range(self.num_tables):\n",
    "#                 hash_key = self.hash(vec, table_index)\n",
    "#                 self.hash_tables[table_index][hash_key].append(i)\n",
    "#         self.balance_hash_tables()\n",
    "\n",
    "#     def euclidean_distance(self, vec1, vec2):\n",
    "#         return np.linalg.norm(vec1 - vec2)\n",
    "    \n",
    "#     def hamming_distance(self, key1, key2):\n",
    "#         return sum(el1 != el2 for el1, el2 in zip(key1, key2))\n",
    "\n",
    "#     def balance_hash_tables(self):\n",
    "#         min_size = 10\n",
    "#         max_size = 50\n",
    "#         for table in self.hash_tables:\n",
    "#             for hash_key in list(table.keys()):\n",
    "#                 if len(table[hash_key]) > max_size:\n",
    "#                     excess_indices = table[hash_key][max_size:]\n",
    "#                     table[hash_key] = table[hash_key][:max_size]\n",
    "#                     # Redistribute excess indices to hash keys with Hamming distance of 1\n",
    "#                     for idx in excess_indices:\n",
    "#                         redistributed = False\n",
    "#                         for other_key in table.keys():\n",
    "#                             if len(table[other_key]) < min_size and self.hamming_distance(hash_key, other_key) == 1:\n",
    "#                                 table[other_key].append(idx)\n",
    "#                                 redistributed = True\n",
    "#                                 break\n",
    "#                         if not redistributed:\n",
    "#                             table[random.choice(list(table.keys()))].append(idx)\n",
    "\n",
    "#     def search(self, query_vec, k):\n",
    "#         candidates = set()\n",
    "#         for table_index in range(self.num_tables):\n",
    "#             hash_key = self.hash(query_vec, table_index)\n",
    "#             if hash_key in self.hash_tables[table_index]:\n",
    "#                 candidates.update(self.hash_tables[table_index][hash_key])\n",
    "#         if not candidates:\n",
    "#             return []\n",
    "#         distances = [(self.euclidean_distance(query_vec, self.index_vectors[i]), i) for i in candidates]\n",
    "#         k_smallest = heapq.nsmallest(k, distances)\n",
    "#         k_smallest_indices = [index for _, index in k_smallest]\n",
    "#         return k_smallest_indices\n",
    "    \n",
    "#     def search_all(self, query_vectors, k):\n",
    "#         return [self.search(query_vec, k) for query_vec in query_vectors]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8421dc36363650c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T12:25:32.578478400Z",
     "start_time": "2024-05-27T12:25:32.483352800Z"
    }
   },
   "outputs": [],
   "source": [
    "#TODO: Write your code for 2.2.2 here\n",
    "# You are allowed to add more arguments to the functions and create more functions if needed.\n",
    "\n",
    "def custom_indexing_algorithm(index_vectors, dim):\n",
    "    \"\"\"\n",
    "    This function builds an index from scratch.\n",
    "    Args:\n",
    "        index_vectors: An array of shape (n_index, dim) containing the index vectors.\n",
    "        dim: The dimensionality of the vectors.\n",
    "    Returns:\n",
    "        An index.\n",
    "    \"\"\"\n",
    "    idx = SimpleLSH()\n",
    "    idx.fit(index_vectors)\n",
    "    # for key, vecs in idx.hash_table.items():\n",
    "    #     print(f\"Hash key: {key} has {len(vecs)} vectors\")\n",
    "    # print(idx.hash_functions)\n",
    "    return idx\n",
    "\n",
    "\n",
    "def custom_index_search(query_vectors, index, k):\n",
    "    \"\"\"\n",
    "    This function searches over the custom index.\n",
    "    Args:\n",
    "        query_vectors: An array of shape (n_queries, dim) containing the query vectors.\n",
    "        index: The custom index.\n",
    "        k: The number of nearest neighbors to retrieve.\n",
    "    \"\"\"\n",
    "    return index.search_all(query_vectors, k)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50f4b92f2ec12fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T21:00:22.662764Z",
     "start_time": "2024-06-10T21:00:22.650804Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add hyperparameters here (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ef371ecd242846db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.84 s\n",
      "Wall time: 5.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.random.seed(0)\n",
    "custom_index = custom_indexing_algorithm(index_vectors, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1c40c61275a3d001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 14.5 s\n",
      "Wall time: 29.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "custom_index_ann = custom_index_search(query_vectors, custom_index, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d083a0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_index_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "3ddba190c55cd0af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T13:30:57.922904800Z",
     "start_time": "2024-05-27T13:30:57.874785600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall@10 for custom_index_search: 0.256\n"
     ]
    }
   ],
   "source": [
    "print(f\"recall@10 for custom_index_search: {compute_recall_at_k(gt_nn2, custom_index_ann, k)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9707f4e593c385ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T21:35:09.991891Z",
     "start_time": "2024-06-10T21:35:09.983920Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
