{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T21:00:36.522780Z",
     "start_time": "2024-06-10T21:00:35.443137Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import spatial \n",
    "import faiss\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f09c59a02a3b0d",
   "metadata": {},
   "source": [
    "## Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a991f1eb012a476",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T21:00:44.538572Z",
     "start_time": "2024-06-10T21:00:44.525608Z"
    }
   },
   "outputs": [],
   "source": [
    "def semi_optimized_exhaustive_search(\n",
    "        index_vectors: np.ndarray,\n",
    "        query_vectors: np.ndarray,\n",
    "        k: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    This function performs an optimized exhaustive search.\n",
    "    Args:\n",
    "        index_vectors: An array of shape (n_index, dim) containing the index vectors.\n",
    "        query_vectors: An array of shape (n_queries, dim) containing the query vectors. \n",
    "        dim: The dimensionality of the vectors.\n",
    "    Returns:\n",
    "        An array of shape (n_queries, k) containing the indices of the k nearest neighbors for each query vector.\n",
    "    \"\"\"\n",
    "    ann_lists = []\n",
    "    for query_vec in query_vectors:\n",
    "        distances = np.linalg.norm(index_vectors - query_vec, axis=1)\n",
    "        ann_lists.append(list(np.argsort(distances)[:k]))\n",
    "    return np.array(ann_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8ef475c717fbe2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T21:00:47.719310Z",
     "start_time": "2024-06-10T21:00:47.698362Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_faiss_flatl2_index(\n",
    "        index_vectors: np.ndarray,\n",
    "        dim: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    This function builds a Faiss flat L2 index.\n",
    "    Args:\n",
    "        index_vectors: An array of shape (n_index, dim) containing the index vectors.\n",
    "        dim: The dimensionality of the vectors. \n",
    "    Returns:\n",
    "        A Faiss flat L2 index.\n",
    "    \"\"\"\n",
    "    index = faiss.IndexFlatL2(dim)\n",
    "    index.add(index_vectors)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1df7a2d698755a82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T21:00:48.174553Z",
     "start_time": "2024-06-10T21:00:48.157599Z"
    }
   },
   "outputs": [],
   "source": [
    "def faiss_search(\n",
    "        query_vectors: np.ndarray,\n",
    "        index: faiss.Index,\n",
    "        k: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    This function uses a Faiss index to search for the k-nearest neighbors of query_vectors.\n",
    "    Args:\n",
    "        query_vectors: An array of shape (n_queries, dim) containing the query vectors. \n",
    "        index: A Faiss index.\n",
    "        k: The number of nearest neighbors to retrieve.\n",
    "    Returns:\n",
    "        An array of shape (, ) containing the indices of the k-nearest neighbors for each query vector.\n",
    "    \"\"\"\n",
    "    distances, indices = index.search(query_vectors, k)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af14bea64023a3d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T21:00:49.337476Z",
     "start_time": "2024-06-10T21:00:49.325508Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_faiss_lsh_index(\n",
    "        index_vectors: np.ndarray,\n",
    "        dim: int,\n",
    "        nbits: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    This function builds a Faiss LSH index.\n",
    "    Args:\n",
    "        index_vectors: An array of shape (n_index, dim) containing the index vectors.\n",
    "        dim: The dimensionality of the vectors. \n",
    "        nbits: The number of bits to use in the hash.\n",
    "    Returns:\n",
    "        A Faiss LSH index.\n",
    "    \"\"\"\n",
    "    index = faiss.IndexLSH(dim, nbits)\n",
    "    index.add(index_vectors)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b4b0932dfa7d7a4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T21:00:49.732824Z",
     "start_time": "2024-06-10T21:00:49.718871Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_recall_at_k(\n",
    "        nn_gt: np.ndarray,\n",
    "        ann: np.ndarray,\n",
    "        k: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    This function computes the recall@k.\n",
    "    Args:\n",
    "        nn_gt: The ground truth nearest neighbors.\n",
    "        ann: The approximate nearest neighbors.\n",
    "        k: The number of nearest neighbors to consider.\n",
    "    Returns:\n",
    "        The recall@k.\n",
    "    \"\"\"\n",
    "    return round(sum([len(set(ann[i]) & set(nn_gt[i])) / k for i in range(len(ann))])/len(ann), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d4be2e90ed842",
   "metadata": {},
   "source": [
    "# 2.1 -- LSH vs Naive Exhaustive Search (Regular Index Vectors)\n",
    "### You just have to run the following cells and add the following results to the report:\n",
    "* running time of the ground truth computation with semi_optimized_exhaustive_search (wall time)\n",
    "* running time of creating faiss_lsh_index (wall time)\n",
    "* running time of faiss_search over query_vectors with faiss_lsh_index (wall time)\n",
    "* recall@10 for faiss_lsh_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4fdbd7671405821",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T21:00:52.378174Z",
     "start_time": "2024-06-10T21:00:52.351252Z"
    }
   },
   "outputs": [],
   "source": [
    "query_vectors = np.load('data/query_vectors.npy')\n",
    "index_vectors = np.load('data/index_vectors.npy')\n",
    "k=10\n",
    "dim = index_vectors.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65ff74d429524ffc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T21:18:41.035362Z",
     "start_time": "2024-06-10T21:18:41.017409Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 22.1 s\n",
      "Wall time: 26.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gt_nn = semi_optimized_exhaustive_search(index_vectors, query_vectors, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd448cbdb96b1ba0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T21:18:36.008226Z",
     "start_time": "2024-06-10T21:18:35.998251Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 18 s\n",
      "Wall time: 5.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "faiss_lsh_index = build_faiss_lsh_index(index_vectors, dim, nbits=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b0a321e6b7406267",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T21:18:32.391344Z",
     "start_time": "2024-06-10T21:18:32.385337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.02 s\n",
      "Wall time: 187 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "faiss_lsh_ann = faiss_search(query_vectors, faiss_lsh_index, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e5554595c4d77a27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T21:18:26.322703Z",
     "start_time": "2024-06-10T21:18:26.233820Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall@10 for faiss_lsh_index: 0.138\n"
     ]
    }
   ],
   "source": [
    "print(f\"recall@10 for faiss_lsh_index: {compute_recall_at_k(gt_nn, faiss_lsh_ann, k)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5ca983b3a893e5",
   "metadata": {},
   "source": [
    "# 2.2 -- Custom Indexing Algorithm\n",
    "Build an indexing algorithm that satisfies the following requirements:\n",
    "* The indexing algorithm should be able to handle vectors of different dimensions\n",
    "* The running time of the indexing should be less than half of the running time of semi_optimized_exhaustive_search), reported in Section 2.1.\n",
    "* The running time of searching over the index should be less than a third (1/3) of the time of the semi_optimized_exhaustive_search function, reported in Section 2.1.\n",
    "* The performance (in terms of recall@10) of the indexing algorithm should be at least 0.8.\n",
    "\n",
    "The last three bullets should also appear in the report.\n",
    "You are allowed to add as many helper functions as you need. You cannot use faiss of scipy libraries for this task. Numpy is allowed. \n",
    "\n",
    "You can also test your algorithm with the additional two query-index sets by replacing the calls made few cells ago to:\n",
    "\n",
    "    query_vectors = np.load('data/query_vectors2.npy')\n",
    "    index_vectors = np.load('data/index_vectors2.npy')\n",
    "or:\n",
    "\n",
    "    query_vectors = np.load('data/query_vectors3.npy')\n",
    "    index_vectors = np.load('data/index_vectors3.npy')\n",
    "    \n",
    "the aforementioned requirements should also be satisfied over these two query-index sets. No need to insert the results over these two to the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8421dc36363650c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T12:25:32.578478400Z",
     "start_time": "2024-05-27T12:25:32.483352800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write your code for 2.2.2 here\n",
    "# You are allowed to add more arguments to the functions and create more functions if needed.\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "class PCA_Kmeans:\n",
    "    def __init__(self, min_clusters=7, max_clusters=15):\n",
    "        # Initialize the PCA_Kmeans class with the min_clusters and max_clusters\n",
    "        \"\"\"\n",
    "        This function initializes the PCA_Kmeans class. \n",
    "        This class will perform PCA to reduce the dimensionality of the index vectors, and then use KMeans to cluster the reduced vectors.\n",
    "        Args:\n",
    "            min_clusters: The minimum number of clusters to consider.\n",
    "            max_clusters: The maximum number of clusters to consider.            \n",
    "        \"\"\"\n",
    "        self.min_clusters = min_clusters\n",
    "        self.max_clusters = max_clusters\n",
    "        self.kmeans = None\n",
    "        self.reduced_vectors = None\n",
    "        self.original_vectors = None\n",
    "        self.pca = None\n",
    "        self.cluster_map = defaultdict(list)\n",
    "        self.cluster_centers = None\n",
    "\n",
    "    def fit(self, index_vectors):\n",
    "        \"\"\"\n",
    "        This function fits the PCA and KMeans models to the index vectors.\n",
    "        Args:\n",
    "            index_vectors: An array of shape (n_index, dim) containing the index vectors.\n",
    "        \"\"\"\n",
    "        self.original_vectors = np.array(index_vectors)\n",
    "        self._perform_pca()\n",
    "        self._find_optimal_clusters_and_kmeans()\n",
    "\n",
    "    def _perform_pca(self):\n",
    "        \"\"\"\n",
    "        This function performs PCA on the original vectors.\n",
    "        \"\"\"\n",
    "        self.pca = PCA(n_components=2)\n",
    "        self.reduced_vectors = self.pca.fit_transform(self.original_vectors)\n",
    "\n",
    "    def _find_optimal_clusters_and_kmeans(self):\n",
    "        \"\"\"\n",
    "        This function finds the optimal number of clusters and fits the KMeans model.\n",
    "        \"\"\"\n",
    "        sse, kmeans_models = self._calculate_sse_and_models()\n",
    "        elbow = self._find_elbow(sse)\n",
    "        self.kmeans = kmeans_models[elbow - self.min_clusters]\n",
    "        self._assign_clusters()\n",
    "\n",
    "    def _calculate_sse_and_models(self):\n",
    "        \"\"\"\n",
    "        This function calculates the sum of squared errors for different numbers of clusters.\n",
    "        Returns:\n",
    "            sse: A list containing the sum of squared errors for different numbers of clusters.\n",
    "            kmeans_models: A list containing the KMeans models for different numbers of clusters.\n",
    "        \"\"\"\n",
    "        sse, kmeans_models = [], []\n",
    "        for k in range(self.min_clusters, self.max_clusters + 1):\n",
    "            kmeans = KMeans(n_clusters=k).fit(self.reduced_vectors)\n",
    "            sse.append(kmeans.inertia_)\n",
    "            kmeans_models.append(kmeans)\n",
    "        return sse, kmeans_models\n",
    "\n",
    "    def _find_elbow(self, sse):\n",
    "        \"\"\"\n",
    "        This function finds the elbow point in the SSE curve.\n",
    "        Args:\n",
    "            sse: A list containing the sum of squared errors for different numbers of clusters.\n",
    "        Returns:\n",
    "            The optimal number of clusters.\n",
    "        \"\"\"\n",
    "        diff2 = np.diff(np.diff(sse))\n",
    "        return np.argmax(diff2) + self.min_clusters + 1\n",
    "\n",
    "    def _assign_clusters(self):\n",
    "        \"\"\"\n",
    "        This function assigns the vectors to clusters.\n",
    "        \"\"\"\n",
    "        self.cluster_centers = self.kmeans.cluster_centers_\n",
    "        cluster_labels = self.kmeans.labels_\n",
    "        for idx, label in enumerate(cluster_labels):\n",
    "            self.cluster_map[label].append(idx)\n",
    "    \n",
    "    def query(self, query_vector, k):\n",
    "        \"\"\"\n",
    "        This function finds the k-nearest neighbors for a query vector.\n",
    "        Args:\n",
    "            query_vector: The query vector.\n",
    "            k: The number of nearest neighbors to retrieve.\n",
    "        Returns:\n",
    "            A list containing the indices of the k-nearest neighbors.\n",
    "        \"\"\"\n",
    "        reduced_query = self.pca.transform([query_vector])[0]\n",
    "        nearest_cluster_idx = self._find_nearest_cluster_idx(reduced_query)\n",
    "        candidate_indices = self.cluster_map[nearest_cluster_idx]\n",
    "        return self._get_k_nearest_neighbors(query_vector, candidate_indices, k)\n",
    "\n",
    "    def _find_nearest_cluster_idx(self, reduced_query):\n",
    "        \"\"\"\n",
    "        This function finds the nearest cluster to a query vector.\n",
    "        Args:\n",
    "            reduced_query: The reduced query vector.\n",
    "        Returns:\n",
    "            The index of the nearest cluster.\n",
    "        \"\"\"\n",
    "        distances = np.linalg.norm(self.cluster_centers - reduced_query, axis=1)\n",
    "        return np.argmin(distances)\n",
    "\n",
    "    def _get_k_nearest_neighbors(self, query_vector, candidate_indices, k):\n",
    "        \"\"\"\n",
    "        This function finds the k-nearest neighbors from a list of candidate indices.\n",
    "        Args:\n",
    "            query_vector: The query vector.\n",
    "            candidate_indices: A list of candidate indices.\n",
    "            k: The number of nearest neighbors to retrieve.\n",
    "        Returns:\n",
    "            A list containing the indices of the k-nearest neighbors.\n",
    "        \"\"\"\n",
    "        distances = np.linalg.norm(self.original_vectors[candidate_indices] - query_vector, axis=1)\n",
    "        nearest_indices = np.argsort(distances)[:k]\n",
    "        return [candidate_indices[i] for i in nearest_indices]\n",
    "\n",
    "    def queries(self, query_vectors, k):\n",
    "        \"\"\"\n",
    "        This function finds the k-nearest neighbors for multiple query vectors.\n",
    "        Args:\n",
    "            query_vectors: An array of shape (n_queries, dim) containing the query vectors.\n",
    "            k: The number of nearest neighbors to retrieve.\n",
    "        Returns:\n",
    "            A list of lists containing the indices of the k-nearest neighbors for each query vector.\n",
    "        \"\"\"\n",
    "        return [self.query(query_vector, k) for query_vector in query_vectors]\n",
    "            \n",
    "\n",
    "def custom_indexing_algorithm(index_vectors, dim):\n",
    "    \"\"\"\n",
    "    This function builds an index from scratch.\n",
    "    Args:\n",
    "        index_vectors: An array of shape (n_index, dim) containing the index vectors.\n",
    "        dim: The dimensionality of the vectors.\n",
    "    Returns:\n",
    "        An index.\n",
    "    \"\"\"\n",
    "    idx = PCA_Kmeans()\n",
    "    idx.fit(index_vectors)\n",
    "    return idx\n",
    "\n",
    "\n",
    "def custom_index_search(query_vectors, index, k):\n",
    "    \"\"\"\n",
    "    This function searches over the custom index.\n",
    "    Args:\n",
    "        query_vectors: An array of shape (n_queries, dim) containing the query vectors.\n",
    "        index: The custom index.\n",
    "        k: The number of nearest neighbors to retrieve.\n",
    "    \"\"\"\n",
    "    gt_nn_pca = index.queries(query_vectors, k)\n",
    "    return gt_nn_pca\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a50f4b92f2ec12fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T21:00:22.662764Z",
     "start_time": "2024-06-10T21:00:22.650804Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add hyperparameters here (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef371ecd242846db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 547 ms\n",
      "Wall time: 469 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "custom_index = custom_indexing_algorithm(index_vectors, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1c40c61275a3d001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.77 s\n",
      "Wall time: 2.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "custom_index_ann = custom_index_search(query_vectors, custom_index, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3ddba190c55cd0af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T13:30:57.922904800Z",
     "start_time": "2024-05-27T13:30:57.874785600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall@10 for custom_index_search: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"recall@10 for custom_index_search: {compute_recall_at_k(gt_nn, custom_index_ann, k)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
