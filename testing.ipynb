{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "from tqdm import tqdm\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2Model.from_pretrained('gpt2')\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'What is the Berry Export Summary 2028 and what is its purpose? 1) Berry was the name chosen by the California government to sell fruit and vegetables and then to expand it into a growing segment. The government decided that an American Indian owned farm could'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'What are some of the benefits reported from having access to Self-supply water sources?\\n\\n1. Water quality is an essential part of your daily routine. A comprehensive review of available groundwater quality information is essential to avoid the harmful contaminants from the water, so you keep your water clean before drinking it (see below). It is best to look up quality levels of drinking water, as they can often change due to contamination.\\n\\nYou can also follow various water resources to get insight into their'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# q = \"What is the Berry Export Summary 2028 and what is its purpose?\"\n",
    "q = \"What are some of the benefits reported from having access to Self-supply water sources?\"\n",
    "\n",
    "generator(q, max_length=100, num_return_sequences=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: What is the capital of France?\n",
      "\n",
      "So when you’re answering questions like that, you might as well give your answer before someone starts sniggering. The answer is “Paris.”\n",
      "\n",
      "In fact, though,\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the open-domain QA pipeline with a pre-trained GPT-Neo model\n",
    "qa_pipeline = pipeline(\"text-generation\", model=\"EleutherAI/gpt-neo-2.7B\")\n",
    "\n",
    "# Define the question\n",
    "question = \"What is the capital of France?\"\n",
    "\n",
    "# Generate the answer\n",
    "result = qa_pipeline(question, do_sample=True)\n",
    "print(f\"Answer: {result[0]['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: What are some of the benefits reported from having access to Self-supply water sources?\n",
      "\n",
      "Many benefits have been noted from having access to water that is self sourced. Some benefits include reduced water use, conservation of water, and reduced water usage\n"
     ]
    }
   ],
   "source": [
    "# Define the question\n",
    "q = \"What are some of the benefits reported from having access to Self-supply water sources?\"\n",
    "\n",
    "# Generate the answer\n",
    "result = qa_pipeline(q, max_length=50, do_sample=True)\n",
    "print(f\"Answer: {result[0]['generated_text']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
